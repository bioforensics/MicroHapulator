{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MicroHapulator: API Demo\n",
    "\n",
    "**MicroHapulator** is software for forensic analysis of microhaplotype sequence data.\n",
    "Features include the following:\n",
    "\n",
    "- simulating simple (single-contributor) and complex (multi-contributor) DNA samples\n",
    "- simulated MPS sequencing of user-specified microhap panels\n",
    "- genotyping of DNA profiles from simple and complex DNA samples\n",
    "- tools for deterministic and probabilistic interpretation of simple and complex samples\n",
    "\n",
    "MicroHapulator relies on microhap marker definitions and allele frequencies from [MicroHapDB](https://github.com/bioforensics/MicroHapDB) and MPS error models included with [InSilicoSeq](https://github.com/HadrienG/InSilicoSeq/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synopsis\n",
    "\n",
    "This notebook provides an interactive demonstration of MicroHapulator's Python API.\n",
    "Readers may also be interested in the CLI demo in [demo-cli.ipynb](demo-cli.ipynb) and the simulation demo in [demo-sim.ipynb](demo-sim.ipynb).\n",
    "\n",
    "To use MicroHapulator in a Python program or interactive Python interpreter, simply load it with `import microhapulator`.\n",
    "Additional functions and classes can also be imported for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import microhapulator\n",
    "from microhapulator.profile import ObservedProfile\n",
    "from microhapulator.type import observe_genotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin the demo proper, let's grab some mock data.\n",
    "See the CLI demo for a description of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -sL https://osf.io/5rmgw/download > reads-EVD1.bam\n",
    "!curl -sL https://osf.io/x8y9j/download > reads-EVD1.bam.bai\n",
    "!curl -sL https://osf.io/jtbr8/download > reads-EVD2.bam\n",
    "!curl -sL https://osf.io/w7c59/download > reads-EVD2.bam.bai\n",
    "!curl -sL https://osf.io/4657h/download > reads-EVD3.bam\n",
    "!curl -sL https://osf.io/g4zqf/download > reads-EVD3.bam.bai\n",
    "    \n",
    "!curl -sL https://osf.io/zdtcn/download > reads-REF1.bam\n",
    "!curl -sL https://osf.io/5t4kd/download > reads-REF1.bam.bai\n",
    "!curl -sL https://osf.io/qakjt/download > reads-REF2.bam\n",
    "!curl -sL https://osf.io/6bjk3/download > reads-REF2.bam.bai\n",
    "!curl -sL https://osf.io/na23r/download > reads-REF3.bam\n",
    "!curl -sL https://osf.io/6vm5u/download > reads-REF3.bam.bai\n",
    "!curl -sL https://osf.io/sh7ya/download > reads-REF4.bam\n",
    "!curl -sL https://osf.io/x9kg6/download > reads-REF4.bam.bai\n",
    "\n",
    "!curl -sL https://osf.io/fjdnq/download > beta-panel.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Genotype Profiles\n",
    "\n",
    "On the command line, the `mhpl8r type` command is used to infer genotype profiles from MPS read alignments.\n",
    "In the Python API, this functionality is implemented in the `ObservedProfile` class or, alternatively, in the `microhapulator.type` module.\n",
    "The following code shows how a genotype profile is inferred from an indexed BAM file and a reference Fasta file containing sequences of the marker target amplicons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MicroHapulator::type] discarded 7206 reads with gaps or missing data at positions of interest\n"
     ]
    }
   ],
   "source": [
    "bamfile = 'reads-REF1.bam'\n",
    "refrfasta = 'beta-panel.fasta'\n",
    "\n",
    "profile = ObservedProfile()\n",
    "for markerid, cov_by_pos, counts, ndiscarded in observe_genotypes(bamfile, refrfasta):\n",
    "    profile.record_coverage(markerid, cov_by_pos, ndiscarded)\n",
    "    for allele, count in counts.items():\n",
    "        profile.record_allele(markerid, allele, count)\n",
    "profile.infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a breakdown of the code.\n",
    "\n",
    "- we create an `ObservedProfile` object\n",
    "- we iterate over the reads using the `observe_genotypes` function; this function aggregates per-base coverage, allele counts, and discarded read counts for each marker\n",
    "- the `profile.record_coverage` method stores the aggregate coverage information\n",
    "- the `profile.record_allele` method stores allele counts\n",
    "- finally, the `profile.infer` method scans the allele counts at each marker and makes a genotype call\n",
    "\n",
    "Alternatively, we can perform the same operation with the `microhapulator.type.type` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MicroHapulator::type] discarded 7206 reads with gaps or missing data at positions of interest\n"
     ]
    }
   ],
   "source": [
    "profile = microhapulator.type.type(bamfile, refrfasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 50 markers in our profile.\n",
    "Let's confirm this and grab the identifiers of the first 5 markers in the profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "['mh17CP-001', 'mh09KK-033', 'mh11KK-037', 'mh04KK-017', 'mh12CP-008']\n"
     ]
    }
   ],
   "source": [
    "markers = list(profile.markers())\n",
    "print(len(markers))\n",
    "print(markers[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can grab the alleles for the genotype called at one of these markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C,G,C,T', 'T,G,C,T'}\n"
     ]
    }
   ],
   "source": [
    "print(profile.alleles('mh13KK-223'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying raw data is stored in a large nested data structure.\n",
    "We can access this data through the `profile.data` member variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_coverage': 994.1,\n",
       " 'min_coverage': 800,\n",
       " 'max_coverage': 998,\n",
       " 'num_discarded_reads': 176,\n",
       " 'allele_counts': {'T,G,C,T': 407,\n",
       "  'T,G,C,G': 2,\n",
       "  'T,G,C,A': 2,\n",
       "  'C,G,C,T': 407,\n",
       "  'C,G,C,G': 2,\n",
       "  'C,G,C,A': 2},\n",
       " 'genotype': [{'allele': 'C,G,C,T', 'haplotype': None},\n",
       "  {'allele': 'T,G,C,T', 'haplotype': None}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile.data['markers']['mh13KK-223']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `json.dumps` function to get a nicer view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"mean_coverage\": 994.1,\n",
      "    \"min_coverage\": 800,\n",
      "    \"max_coverage\": 998,\n",
      "    \"num_discarded_reads\": 176,\n",
      "    \"allele_counts\": {\n",
      "        \"T,G,C,T\": 407,\n",
      "        \"T,G,C,G\": 2,\n",
      "        \"T,G,C,A\": 2,\n",
      "        \"C,G,C,T\": 407,\n",
      "        \"C,G,C,G\": 2,\n",
      "        \"C,G,C,A\": 2\n",
      "    },\n",
      "    \"genotype\": [\n",
      "        {\n",
      "            \"allele\": \"C,G,C,T\",\n",
      "            \"haplotype\": null\n",
      "        },\n",
      "        {\n",
      "            \"allele\": \"T,G,C,T\",\n",
      "            \"haplotype\": null\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(profile.data['markers']['mh13KK-223'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, when saving a profile, it is this raw data that is rendered in JSON and written to an output file.\n",
    "(The `profile.dump` method is a wrapper around the `json.dump` function.)\n",
    "We can then construct a new profile object from the JSON file stored on disk.\n",
    "The following code round-trips the profile from memory to disk and then back into memory.\n",
    "The `==` operator simply checks whether two `Profile` objects have the same allele calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile.dump('profile.json')\n",
    "profile_copy = ObservedProfile(fromfile='profile.json')\n",
    "profile == profile_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-source Profile Comparisons\n",
    "\n",
    "We can easily replicate the analyses described in the [CLI demo](demo-cli.ipynb) using the Python API.\n",
    "First let's infer genotype profiles for each sample in Scenario 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MicroHapulator::type] discarded 654 reads with gaps or missing data at positions of interest\n",
      "[MicroHapulator::type] discarded 666 reads with gaps or missing data at positions of interest\n",
      "[MicroHapulator::type] discarded 7206 reads with gaps or missing data at positions of interest\n"
     ]
    }
   ],
   "source": [
    "evd1 = microhapulator.type.type('reads-EVD1.bam', 'beta-panel.fasta')\n",
    "evd2 = microhapulator.type.type('reads-EVD2.bam', 'beta-panel.fasta')\n",
    "ref1 = microhapulator.type.type('reads-REF1.bam', 'beta-panel.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the Hamming distance between two profiles using the `microhapulator.dist.dist` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microhapulator.dist.dist(ref1, evd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microhapulator.dist.dist(ref1, evd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `rand_match_prob` method of `ObservedProfile` objects to compute the RMP, and the `rmp_lr_test` to compute the LR test statistic as described in the CLI demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.840230248298337e-60"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmp = ref1.rand_match_prob('SA004108N')\n",
    "rmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6040105289080383e+59"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrt_stat = ref1.rmp_lr_test(evd1, 'SA004108N')\n",
    "lrt_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6040105289080417e-115"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrt_stat = ref1.rmp_lr_test(evd2, 'SA004108N')\n",
    "lrt_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture Analysis\n",
    "\n",
    "The following code reproduces the analysis of Scenario 2 in the CLI demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MicroHapulator::type] discarded 3674 reads with gaps or missing data at positions of interest\n",
      "[MicroHapulator::type] discarded 7483 reads with gaps or missing data at positions of interest\n",
      "[MicroHapulator::type] discarded 7280 reads with gaps or missing data at positions of interest\n",
      "[MicroHapulator::type] discarded 7456 reads with gaps or missing data at positions of interest\n"
     ]
    }
   ],
   "source": [
    "evd3 = microhapulator.type.type('reads-EVD3.bam', 'beta-panel.fasta')\n",
    "ref2 = microhapulator.type.type('reads-REF2.bam', 'beta-panel.fasta')\n",
    "ref3 = microhapulator.type.type('reads-REF3.bam', 'beta-panel.fasta')\n",
    "ref4 = microhapulator.type.type('reads-REF4.bam', 'beta-panel.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum contributors in sample: 3\n",
      "    - number of supporting markers with max allele count: 3\n",
      "    - percentage of markers overall with max allele count: 0.06\n"
     ]
    }
   ],
   "source": [
    "min_contrib, num_markers, perc_markers = microhapulator.contrib.contrib(evd3)\n",
    "print('Minimum contributors in sample:', min_contrib)\n",
    "print('    - number of supporting markers with max allele count:', num_markers)\n",
    "print('    - percentage of markers overall with max allele count:', perc_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REF2 vs EVD3: 83/83 (1.000)\n",
      "REF3 vs EVD3: 60/84 (0.714)\n",
      "REF4 vs EVD3: 60/86 (0.698)\n"
     ]
    }
   ],
   "source": [
    "for ref, label in zip((ref2, ref3, ref4), ('REF2', 'REF3', 'REF4')):\n",
    "    contained, total = microhapulator.contain.contain(evd3, ref)\n",
    "    output = '{:s} vs EVD3: {:d}/{:d} ({:.3f})'.format(label, contained, total, contained / total)\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
