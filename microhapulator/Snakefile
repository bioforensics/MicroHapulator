from base64 import b64encode
from datetime import datetime
from glob import glob
from jinja2 import Template
import json
from matplotlib import pyplot as plt
import microhapulator
from microhapulator.profile import TypingResult
from os import symlink
from pkg_resources import resource_filename
import pandas as pd
import sys


def full_reference_index_files():
    filename = resource_filename("microhapulator", "data/hg38.fasta.gz")
    filenames = [filename]
    for suffix in ("amb", "ann", "bwt", "pac", "sa"):
        idxfile = f"{filename}.{suffix}"
        filenames.append(idxfile)
    return filenames


def parse_flash_summary(logfile):
    with open(logfile, "r") as fh:
        data = fh.read()
        tp = re.search(r"Total pairs:\s+(\d+)", data).group(1)
        cp = re.search(r"Combined pairs:\s+(\d+)", data).group(1)
        ip = re.search(r"Innie pairs:\s+(\d+)", data).group(1)
        op = re.search(r"Outie pairs:\s+(\d+)", data).group(1)
        up = re.search(r"Uncombined pairs:\s+(\d+)", data).group(1)
        return int(tp), int(cp), int(ip), int(op), int(up)


def parse_read_counts(logfile):
    with open(logfile, "r") as fh:
        line = next(fh)
        totalreads = line.strip().split()[-1]
        line = next(fh)
        mappedreads = line.strip().split()[-1]
        return int(totalreads), int(mappedreads)


def parse_balance_stat(logfile):
    with open(logfile, "r") as fh:
        line = next(fh)
        stat = line.strip().split()[-1]
        return float(stat)


rule report:
    input:
        "analysis/summary.tsv",
        expand("analysis/{sample}/{sample}-type.json", sample=SAMPLES),
        expand("analysis/{sample}/{sample}-r1-read-lengths.png", sample=SAMPLES),
        expand("analysis/{sample}/{sample}-r2-read-lengths.png", sample=SAMPLES),
        expand("analysis/{sample}/{sample}-merged-read-lengths.png", sample=SAMPLES),
        expand("analysis/{sample}/{sample}-interlocus-balance.png", sample=SAMPLES),
        expand("analysis/{sample}/{sample}-heterozygote-balance.png", sample=SAMPLES),
        expand("analysis/{sample}/fastqc/R{end}-fastqc.html", sample=SAMPLES, end=(1, 2)),
        "template.html",
    output:
        "report.html",
    run:
        summary = pd.read_csv("analysis/summary.tsv", sep="\t")
        r1readlenplots = list()
        r2readlenplots = list()
        mergedreadlenplots = list()
        locbalanceplots = list()
        hetbalanceplots = list()
        for sample in SAMPLES:
            with open(f"analysis/{sample}/{sample}-r1-read-lengths.png", "rb") as fh:
                data = b64encode(fh.read()).decode("ascii")
                r1readlenplots.append(data)
            with open(f"analysis/{sample}/{sample}-r2-read-lengths.png", "rb") as fh:
                data = b64encode(fh.read()).decode("ascii")
                r2readlenplots.append(data)
            with open(f"analysis/{sample}/{sample}-merged-read-lengths.png", "rb") as fh:
                data = b64encode(fh.read()).decode("ascii")
                mergedreadlenplots.append(data)
            with open(f"analysis/{sample}/{sample}-interlocus-balance.png", "rb") as fh:
                data = b64encode(fh.read()).decode("ascii")
                locbalanceplots.append(data)
            with open(f"analysis/{sample}/{sample}-heterozygote-balance.png", "rb") as fh:
                data = b64encode(fh.read()).decode("ascii")
                hetbalanceplots.append(data)
        with open("template.html", "r") as infh, open("report.html", "w") as outfh:
            template = Template(infh.read())
            output = template.render(
                date=datetime.now().replace(microsecond=0).isoformat(),
                mhpl8rversion=microhapulator.__version__,
                samples=SAMPLES,
                summary=summary,
                r1readlenplots=r1readlenplots,
                r2readlenplots=r2readlenplots,
                mergedreadlenplots=mergedreadlenplots,
                locbalanceplots=locbalanceplots,
                hetbalanceplots=hetbalanceplots,
                static=5,
                dynamic=0.02,
                zip=zip,
            )
            print(output, file=outfh, end="")


rule summary:
    input:
        expand("analysis/{sample}/flash.log", sample=config["samples"]),
        expand("analysis/{sample}/{sample}-mapped-reads.txt", sample=config["samples"]),
        expand(
            "analysis/{sample}/fullrefr/{sample}-fullrefr-mapped-reads.txt",
            sample=config["samples"],
        ),
        expand("analysis/{sample}/{sample}-typing-rate.tsv", sample=config["samples"]),
        expand("analysis/{sample}/{sample}-interlocus-balance-chisq.txt", sample=config["samples"]),
        expand(
            "analysis/{sample}/{sample}-heterozygote-balance-pttest.txt",
            sample=config["samples"],
        ),
    output:
        tsv="analysis/summary.tsv",
    run:
        columns = (
            "Sample",
            "TotalReads",
            "Merged",
            "MergeRate",
            "Mapped",
            "MappingRate",
            "MappedFullRefr",
            "MappingRateFullRefr",
            "Typed",
            "TypingRate",
            "InterlocChiSq",
            "HetTstat",
        )
        data = {colname: [] for colname in columns}
        for sample in sorted(config["samples"]):
            print(f"[Compiling summary] Sample={sample}", file=sys.stderr)
            totalreads, mergedreads, *_ = parse_flash_summary(f"analysis/{sample}/flash.log")
            maptotal, mapped = parse_read_counts(f"analysis/{sample}/{sample}-mapped-reads.txt")
            assert maptotal == mergedreads, (sample, maptotal, mergedreads)
            frmaptotal, frmapped = parse_read_counts(
        f"analysis/{sample}/{sample}-fullrefr-mapped-reads.txt"
            )
            assert (
                frmaptotal == maptotal
            ), f"Sample={sample} fullrefr map total={frmaptotal} map total={maptotal}"
            typing = pd.read_csv(f"analysis/{sample}/{sample}-typing-rate.tsv", sep="\t")
            num_typed_reads = typing.TypedReads.sum()
            typing_total_reads = typing.TotalReads.sum()
            # assert typing_total_reads == mapped, f"Sample={sample} type total={typing_total_reads} mapped={mapped}"
            typing_rate = num_typed_reads / typing_total_reads
            chisq = parse_balance_stat(f"analysis/{sample}/{sample}-interlocus-balance-chisq.txt")
            tstat = parse_balance_stat(
                f"analysis/{sample}/{sample}-heterozygote-balance-pttest.txt"
            )
            data["Sample"].append(sample)
            data["TotalReads"].append(totalreads)
            data["Merged"].append(mergedreads)
            data["MergeRate"].append(mergedreads / totalreads)
            data["Mapped"].append(mapped)
            data["MappingRate"].append(mapped / maptotal)
            data["MappedFullRefr"].append(frmapped)
            data["MappingRateFullRefr"].append(frmapped / frmaptotal)
            data["Typed"].append(num_typed_reads)
            data["TypingRate"].append(typing_rate)
            data["InterlocChiSq"].append(chisq)
            data["HetTstat"].append(tstat)
        df = pd.DataFrame(data)
        df.to_csv(output.tsv, sep="\t", index=False, float_format="%.4f")


rule fastqc:
    input:
        lambda wildcards: sorted([fq for fq in config["readfiles"] if wildcards.sample in fq]),
    output:
        r1="analysis/{sample}/fastqc/R1-fastqc.html",
        r2="analysis/{sample}/fastqc/R2-fastqc.html",
    threads: 2
    run:
        shell("fastqc --outdir analysis/{wildcards.sample}/fastqc/ --threads {threads} {input}")
        outfiles = sorted(glob(f"analysis/{wildcards.sample}/fastqc/*.html"))
        for end, outfile in enumerate(outfiles, 1):
            outfile = Path(outfile)
            linkfile = f"analysis/{wildcards.sample}/fastqc/R{end}-fastqc.html"
            symlink(outfile.name, linkfile)


rule merge:
    input:
        lambda wildcards: sorted([fq for fq in config["readfiles"] if wildcards.sample in fq]),
    output:
        mergedfq="analysis/{sample}/{sample}.extendedFrags.fastq",
        log="analysis/{sample}/flash.log",
    threads: 8
    shell:
        """
        flash --min-overlap=25 --max-overlap=300 --allow-outies \
            --threads={threads} --max-mismatch-density=0.25 \
            --output-prefix analysis/{wildcards.sample}/{wildcards.sample} \
            {input} \
            2>&1 | tee {output.log}
        """


rule read_length_distributions:
    input:
        lambda wildcards: sorted([fq for fq in config["readfiles"] if wildcards.sample in fq]),
        rules.merge.output.mergedfq,
    output:
        r1="analysis/{sample}/{sample}-r1-read-lengths.png",
        r2="analysis/{sample}/{sample}-r2-read-lengths.png",
        merged="analysis/{sample}/{sample}-merged-read-lengths.png",
    run:
        r1 = ("analysis/{sample}/{sample}-r1-read-lengths.png",)
        r2 = ("analysis/{sample}/{sample}-r2-read-lengths.png",)
        merged = ("analysis/{sample}/{sample}-merged-read-lengths.png",)
    run:
        microhapulator.api.read_length_dist(
            input[0],
            output.r1,
            xlim=(0, 300),
            title=f"{wildcards.sample} R1",
        )
        microhapulator.api.read_length_dist(
            input[1],
            output.r2,
            xlim=(0, 300),
            title=f"{wildcards.sample} R2",
        )
        microhapulator.api.read_length_dist(
            input[2],
            output.merged,
            xlabel="Length of Merged Read Pair (bp)",
            xlim=(0, 500),
            title=wildcards.sample,
        )


rule map_sort_and_index:
    input:
        refr=config["mhrefr"],
        fastq=rules.merge.output.mergedfq,
    output:
        bam="analysis/{sample}/{sample}.bam",
        bai="analysis/{sample}/{sample}.bam.bai",
        counts="analysis/{sample}/{sample}-mapped-reads.txt",
    threads: 32
    shell:
        """
        bwa mem -t {threads} {input} | samtools view -b | samtools sort -o {output.bam}
        samtools index {output.bam}
        echo -n "Total reads: " > {output.counts}
        samtools view -c -F 2304 {output.bam} >> {output.counts}
        echo -n "Mapped reads: " >> {output.counts}
        samtools view -c -F 2308 {output.bam} >> {output.counts}
        """


rule call_haplotypes:
    input:
        marker_defn=config["mhdefn"],
        bam=rules.map_sort_and_index.output.bam,
    output:
        typing_result="analysis/{sample}/{sample}-type-raw.json",
    shell:
        "mhpl8r type {input} --out {output}"


rule check_typing_rate:
    input:
        json=rules.call_haplotypes.output.typing_result,
    output:
        tsv="analysis/{sample}/{sample}-typing-rate.tsv",
    run:
        result = TypingResult(fromfile=input.json)
        rates = result.typing_rate()
        rates.to_csv(output.tsv, sep="\t", index=False, float_format="%.4f")


rule apply_filters:
    input:
        json=rules.call_haplotypes.output.typing_result,
    output:
        genotype_call="analysis/{sample}/{sample}-type.json",
    shell:
        "mhpl8r filter {input} --out {output} --static 5 --dynamic 0.02"


rule interlocus_balance:
    input:
        result=rules.apply_filters.output.genotype_call,
    output:
        counts="analysis/{sample}/{sample}-marker-read-counts.csv",
        plot="analysis/{sample}/{sample}-interlocus-balance.png",
        log="analysis/{sample}/{sample}-interlocus-balance-chisq.txt",
    shell:
        """
        mhpl8r locbalance {input} --csv {output.counts} --figure {output.plot} --title {wildcards.sample} --quiet \
            | tee {output.log}
        """


rule heterozygote_balance:
    input:
        result=rules.apply_filters.output.genotype_call,
    output:
        counts="analysis/{sample}/{sample}-het-marker-allele-counts.csv",
        plot="analysis/{sample}/{sample}-heterozygote-balance.png",
        log="analysis/{sample}/{sample}-heterozygote-balance-pttest.txt",
    shell:
        """
        mhpl8r hetbalance {input} --csv {output.counts} --figure {output.plot} --title {wildcards.sample} --labels \
            | tee {output.log}
        """


rule download_full_reference:
    output:
        full_reference_index_files(),
    shell:
        "mhpl8r getrefr"


rule map_full_reference:
    input:
        refr=resource_filename("microhapulator", "data/hg38.fasta.gz"),
        fastq=rules.merge.output.mergedfq,
    output:
        bam="analysis/{sample}/fullrefr/{sample}-fullrefr.bam",
        bai="analysis/{sample}/fullrefr/{sample}-fullrefr.bam.bai",
        counts="analysis/{sample}/fullrefr/{sample}-fullrefr-mapped-reads.txt",
    threads: 32
    shell:
        """
        bwa mem -t {threads} {input} | samtools view -b | samtools sort -o {output.bam}
        samtools index {output.bam}
        echo -n "Total reads: " > {output.counts}
        samtools view -c -F 2304 {output.bam} >> {output.counts}
        echo -n "Mapped reads: " >> {output.counts}
        samtools view -c -F 2308 {output.bam} >> {output.counts}
        """
